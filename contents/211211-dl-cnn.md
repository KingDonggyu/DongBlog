---
date: "2021-12-11"
title: "[Deep Learning] CNN"
category: "Data Science"
categoryColor: "seagreen"
tags: ["AI", "DL"]
thumbnail: "./images/DL.jpeg"
---

# Convolutional Layer

<hr />

<div style="text-align:center;">
   <img src="https://user-images.githubusercontent.com/33220404/145670589-fb1bc8a3-250f-4aaa-af72-2027c43fd1d3.png" width="600">
</div>

- **첫 번째 합성곱 층**의 뉴런은 입력 이미지의 모든 픽셀에 연결되지 않고, 합성곱 층 뉴런의 수용영역 안에 있는 픽셀에만 연결한다.

- **두 번째 합성곱 층**의 각 뉴런은 첫 번째 층의 작은 사각 영역 안에 위치한 뉴런에 연결한다.

> 이런 구조를 통해 네트워크가 첫 번째 은닉층에서는 작은 저수준 특성에 집중하고, 그 다음 은닉층에서는 더 큰 고수준 특성으로 조합해 나갈 수 있다.

## Dense Layer vs. Convolutional Layer

<div style="text-align:center;">
   <img src="https://user-images.githubusercontent.com/33220404/145670773-c97b1f14-7ae8-495f-a99e-86ba911a245a.png" width="600">
</div>

입력층의 모든 노드는 다음 은닉층의 모든 단일 노드에 연결될 때 이를 **'Dense Layer'** 또는 **'Fully Connected Layer'** 라 한다.

<br />

<div style="text-align:center;">
   <img src="https://user-images.githubusercontent.com/33220404/145670780-91c56827-d351-4d1d-9983-759a03471532.png" width="900">
</div>

반면, 합성곱 층은 위 이미지를 예시로 보았을 때 은닉층의 첫 번째 노드는 입력층의 5\*5만 차지한다.

- **Layer가 깊어질수록 size가 작아진다. ➡️ 추상적인 개념에서 더 중요하고 관심있는 것으로 변환한다.**

<br />

## Padding

> 합성곱 연산을 수행하기 전, 입력 데이터 주변을 특정값으로 채워 늘리는 것이다.

<div style="text-align:center;">
   <img src="https://user-images.githubusercontent.com/33220404/145670911-75f59aa2-a19e-493b-8e54-00e4749d0c5f.png" width="500">
</div>

**층의 높이와 너비를 이전 층과 같게 하기 위해 입력의 주위에 0을 추가하는 것이 일반적이다. ➡️ Zero Padding**

CNN에서는 각 층이 2D로 표현되므로, 뉴런을 그에 상응하는 입력과 연결하기 더 쉽다.

<br />

<div style="text-align:center;">
   <img src="https://user-images.githubusercontent.com/33220404/145671085-61f1cee2-9252-45a7-bae7-b564a5b9aca3.png" width="500">
</div>

입력 데이터에 필터를 적용할 때, 필터가 이동할 간격을 **stride**라 한다. (한 수용영역과 다음 수용영역 사이의 간격)

- 스트라이드를 2로 설정하면 size가 두 배 줄어든다.

**수용영역 사이에 간격을 두어 큰 입력층을 훨씬 작은 층에 연결할 수 있다. 이는 모델의 계산 복잡도를 낮춘다.**

<br />

## Filters

> 입력의 새로운 표현(원하는 핵심 개념만 다음 Layer로 전달)을 'Filters'(또는 합성곱 커널)이라 한다. 이는 각 뉴런의 가중치 집합으로, 뉴런의 가중치는 작은 이미지, 즉 수용 필드의 크기로 나타낼 수 있다.

<div style="text-align:center;">
   <img src="https://user-images.githubusercontent.com/33220404/145671330-0683e12f-93dc-4586-8cd8-eccdef4a1f3f.png" width="600">
</div>

위 이미지의 첫 번째는 가운데 흰 수직선이 있는 검은 사각형(가운데 열은 1, 그 외는 모두 0인 7\*7 행렬)이다.

- 이런 가중치의 뉴런은 가운데 수직선 제외 수용 필드의 모든 것을 무시한다.

위 이미지의 두 번째는 가운데 흰 수평선이 있는 검은 사각형이다.

- 이런 가중치의 뉴런은 가운데 수평선 제외 수용 필드의 모든 것을 무시한다.

그림의 입력 이미지를 네트워크에 주입하고, 한 층의 모든 뉴런에 같은 **수직선 필터를 적용**하면 왼쪽과 같이 이미지의 세로선에 해당하는 부분이 출력될 것이고, **수평선 필터를 적용**하면 오른쪽과 같이 이미지의 가로선에 해당하는 부분이 출력될 것이다.

**➡️ 층의 전체 뉴런에 적용된 하나의 필터는 하나의 <u>Feature Map</u>을 만든다.**

> 여러 개의 필터를 사용해 이미지의 세부 특징을 추출해 학습을 진행하여, CNN은 합성곱 층이 학습을 통해 자동으로 가장 유용한 필터를 찾고 상위 층은 이들을 연결해 더 복잡한 패턴을 학습한다.

## Convolution Operation

<div style="text-align:center;">
  <img src="https://user-images.githubusercontent.com/33220404/145671257-85cd51c5-136f-4801-aee2-29a7493f2944.png" width="500">
  <img src="https://user-images.githubusercontent.com/33220404/145671262-522a08a2-ecd5-4771-b112-0f55b9637598.png" width="500">
</div>

<div style="text-align:center;">
  <img src="https://user-images.githubusercontent.com/33220404/145671272-5ddccf98-9c30-4490-994e-cd2fd404e906.png" width="500">
  <img src="https://user-images.githubusercontent.com/33220404/145671280-8f6d283a-e1dc-40ea-8707-386317ed8563.png" width="500">
</div>

<br />

## Stacking Multiple Feature Maps

<div style="text-align:center;">
   <img src="https://user-images.githubusercontent.com/33220404/145671605-5f4ae69e-5c36-48aa-b85e-a895f55d1471.png" width="500">
</div>

실제 합성곱 층은 여러가지 필터를 가지고 필터마다 하나의 특성 맵을 출력하므로, 합성곱 층의 출력을 3D로 표현하는 것이 더 정확하다.

- 각 특성 맵의 픽셀은 하나의 뉴런에 해당한다.

- 하나의 특성 맵 안에서는 모든 뉴런이 같은 파라미터(가중치, 편향)를 공유하지만, 다른 특성 맵의 뉴런은 다른 파라미터를 사용한다.

- 한 뉴런의 수용필드는 이전 층의 모든 특성 맵에 걸쳐 확장된다.

**➡️ 하나의 합성곱 층이 입력에 여러 필터를 동시에 적용해 입력의 여러 특성을 감지할 수 있다.**

**<u>다만, 어떤 가중치가 좋은지 확인할려면 모든 가중치를 전부 확인해야 하므로 시간이 오래 걸리며, 합성곱 층이 많은 양의 RAM을 필요로 한다는 단점이 있다.</u>**

<br />

# Polling Layer

<hr />

> Polling Layer의 목적은 계산량과 메모리 사용량, 파라미터 수를 줄이기 위해 입력 이미지의 부표본(즉, 축소본)을 생성하는 것이다. 이는 결과값의 차원을 축소한다.

합성곱 층과 마찬가지로, 풀링 층의 각 뉴런은 이전 층의 작은 사각 영역의 수용 필드에 있는 뉴런의 출력과 연결되어 있다.

계산하여 대표 값을 넘겨줘야 하므로 가중치가 필요한 합성곱 층과 달리, **풀링 뉴런은 크기, 스트라이드, 패딩 유형을 지정해야 하지만, 가중치가 없다.** 즉, 최대나 평균 같은 합산 함수로 입력값을 더하는 것이 전부이다.

<br />

## Max Pooling Layer

<div>
   <img src="https://user-images.githubusercontent.com/33220404/145672006-1a50924c-f0f9-4c0d-88c9-ee031cda9593.png" width="700">
</div>

각 수용필드에서 **가장 큰 입력값이 다음 층으로 전달**되고, 나머지는 버려진다.

<br />

<div>
   <img src="https://user-images.githubusercontent.com/33220404/145672088-2c516c65-2725-4f00-8129-c03c12cf02f5.png" width="500">
</div>

**최대 풀링은 작은 변화에도 일정 수준의 invariance(불변성)을 만든다.**

- 위 이미지는 위치만 이동시킨 같은 이미지 A, B, C가 있고, 2\*2 커널, 스트라이드 2인 최대 풀링층을 통과한다. 이 때, 이미지 A와 B에서 최대 풀링층의 출력이 동일한데, 이는 **이동 불변성**을 뜻한다.

- 이러한 불변성은 분류 작업처럼 예측이 이런 작은 부분에서 영향을 받지 않는 경우 유용하다.

- **작은 이동에 대해 똑같은 개체로 판별할 수 있으므로, 너무 민감하지 않고 detaildp 너무 의존하지 않는다는 점이 장점이 될 수 있지만, detail을 신경써야 할 때는 좋지 않다.**

<br />

**최대 풀링은 파괴적이다.**

- 2\*2 커널, 스트라이드 2를 사용하더라도 출력시 입력값의 75%를 잃게 된다.

- 불변성이 아닌 **등변성**이 목표인 경우, 입력의 작은 변화도 출력에서 그에 사응하는 작은 변화로 이루어져야 하므로 유용하지 않다.

<br />

# Implementing A Simple CNN Architecture

<hr />

## Typical CNNs

일반적인 CNN 아키텍처는 몇 개의 컨볼루션 레이어를 쌓는다.

→ a pooling layer
→ convolutional layers
→ pooling layer
→ convolutional layers
→ pooling layer
→ and so on.

<br />

**Typical CNN architecture**

<div>
   <img src="https://user-images.githubusercontent.com/33220404/145672366-b8d6c758-4581-4586-89ae-237820f1d7a8.png" width="500">
</div>

<br />

## Simple CNN Code

```python
model = keras.models.Sequential([
    keras.layers.Conv2D(64, 7, activation="relu", padding="same",
        input_shape=[28, 28, 1])  # input 해상도가 더 크면 pooling layer를 더 넣어주면 된다.
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Flatten(),  # 데이터 배열이 몇 차원이든 모두 1차원으로 바꿔 읽기 쉽게 해주는 함수
    keras.layers.Dense(128, activation="relu"),
    keras.laeyrs.Dropout(0.5),
    keras.layers.Dense(64, activation="relu"),
    keras.laeyrs.Dropout(0.5),
    keras.layers.Dense(10, activation="softmax"),

    # 더 큰 이미지의 경우 이 구조를 몇 번 더 반복할 수 있다.
])
```

Note of **Conv2D** : 필터 수는 출력 레이어를 향해 늘어난다. (64 → 128 → 256)

- **Low-level features**: little

- **High-level**: needs many

- **Why?** **`strides`를 1로, `padding`을 'same'으로 주게되면** 컨볼루션 레이어의 높이와 너비가 이전 컨볼루션 레이어와 동일하게 된다. 컨볼루션 레이어는 각 필터 당 하나의 activation map을 갖기 때문에 **필터의 개수는 컨볼루션 레이어의 뎁스에 영향을 주는 인자가 된다.** **그러므로 대게의 경우에 있어 점진적으로 필터의 수가 증가하게 설계를 해주어야 한다.**

<br />

Note of **Pooling**: `MaxPooling(2)` 덕분에 복잡성이 감소했다.

- 해상도가 줄어든다. (28\*28 ➔ 14\*14 ➔ 7\*7 ➔ 3\*3)

<br />

Note of **Dense**: 입력을 **평면화**해야 한다.

- dense 네트워크는 각 인스턴스에 대해 features의 **1D array**을 기대하기 때문이다.

<br />
<br />

**Source:**

📖 모두의 딥러닝, 2/E, 2020

📖 핸즈온머신러닝, 2/E, 2020 (번역)
