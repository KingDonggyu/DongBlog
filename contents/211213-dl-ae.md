---
date: "2021-12-13"
title: "[Deep Learning] Autoencoder (AE)"
category: "Data Science"
categoryColor: "seagreen"
tags: ["AI", "DL"]
thumbnail: "./images/DL.jpeg"
---

> Autoencoders(AE)는 supervision(감독, 지도) 없이 입력 데이터의 latent(잠재된/내재된) 표현 또는 코딩이라 부르는 입력 데이터의 밀집 표현을 학습할 수 있는 NN이다.

감독되지 않은 방식 즉, **훈련세트에 레이블이 지정되지 않음**을 뜻한다.

AE는 일반적으로 입력 데이터보다 차원이 훨씬 낮으므로 차원 축소, 특히 시각화에 사용된다. (AE가 강력한 features 추출기처럼 작동하므로 심층 신경망의 비지도 사전 훈련에 사용된다.)

**AE는 훈련 데이터와 매우 비슷한 새로운 데이터를 생성할 수 있다.**

훈련하는 동안 AE에 제약을 가해서 데이터에 있는 패턴을 찾아 활용한다.

# Simple Autoencoder

<hr />

<div style="text-align:center">
  <img src="https://user-images.githubusercontent.com/33220404/145704981-376805c8-ab47-430c-b99a-dd82eb08d5cd.png" width="300">
</div>

- AE는 입력을 내부 표현으로 바꾸는 **인코더**, 내부 표현을 출력으로 바꾸는 **디코더**로 항상 구성되어 있다.

  - AE가 입력을 **재구성(Reconstructions)**하기 때문에 출력을 재구성 이라고 부르고, 비용 함수는 재구성이 입력과 다를 때 모델에 벌점을 부과하는 재구성 손실을 포함한다.

- 출력층의 뉴런 수가 입력 개수와 동일하다는 것을 제외하면, AE는 일반적으로 **Multi-Layer Perceptron(MLP)** 와 동일한 아키텍처를 가지고 있다.

<br />

내부의 표현이 입력 데이터보다 저차원이기 때문에, 이러한 AE를 **Undercomplete(과소완전)** AE라 한다.

- 과소완전 AE는 입력을 코딩으로 간단히 복사할 수 없으며, 입력과 똑같은 것을 출력하기 위한 방법을 찾아야 한다.

- 이를 통해 **입력 데이터에서 가장 중요한 features를 학습하도록 만든다.** 적어도 입력 데이터에 대해서는 복원(재구성)을 잘한다는 특징이 있다.

<br />

**AE가 선형 활성화만 사용하고 비용 함수가 MSE이면 PCA를 수행하게 된다.** (Undercomplete Linear Autoencoder ➔ performing PCA)

- 1. 데이터에 가장 가까운 **hyperplane 식별**

- 2. 데이터를 해당 hyperplane에 **project(투영)**

<br />

# Stacked Autoencoders

<hr />

> 은닉층을 여러개 가지는 AE이다. 층을 더 추가하여 더 복잡한 코딩을 학습할 수 있고, AE가 너무 강력해지지 않도록 주의한다.

인코더가 너무 강력해서 각각의 입력 데이터를 임의의 한 숫자로 매핑하도록 학습했다고 가정했을 때, 훈련 데이터를 완벽히 재구성하겠지만 유용한 데이터 표현을 학습하지 못할 것이다.

<div style="text-align:center">
  <img src="https://user-images.githubusercontent.com/33220404/145705421-e832099c-888d-464c-b169-6c79d8e7a0f4.png" width="500">
</div>

- **적층 AE는 전형적으로 가운데 은닉층(코딩층)을 기준으로 대칭(symmetrical)이다.** 위 예시는 입력 784개, 뉴런 300개로 된 은닉층, 뉴런 150개로 된 은닉층, 뉴런 300개로 된 은닉층, 뉴런 784개로 된 출력층으로 이루어져있다.

<br />

## Visualization

<div style="text-align:center">
  <img src="https://user-images.githubusercontent.com/33220404/145705583-2a3e2f8a-73f3-45b6-8565-be5dcc704d17.png" width="500">
</div>

top: **Original** 이미지, bottom: **Reconstructions(재구성)**

- AE가 잘 훈련되었는지 확인하는 방법은 **입력과 출력을 비교**하는 것이다. 입력과 출력의 차이가 크지 않아야 한다.

- 모델을 더 훈련하고 인코더/디코더 층을 늘리거나 코딩을 늘리면 나아질 수 있으나, 네**트워크가 너무 강력하면 데이터에서 유익한 패턴을 학습하지 못하고 완벽한 재구성 이미지를 만들려고 한다.**

<br />

## Recurrent Autoencoders

시계열 또는 텍스트(비지도 학습 또는 차원축소) 시퀀스에 대한 AE를 구축하려는 경우, **RNN이 dense 네트워크(MLP, CNN)보다 더 적합할 수 있다.**

- **Encoder**: 일반적으로 **sequence-to-vetor RNN**

- **Decoder**: 일반적으로 **vector-to-sequence RNN**

<br />

# Overcomplete AE

<hr />

## Denoising Autoencoders (DAE)

> AE가 유용한 기능을 배우도록 하는 또 다른 방법은 입력에 노이즈를 추가하는 것이다. 원래(노이즈 없는) 입력을 복구하도록 학습한다.

What noise?

- 입력에 순수한 가우시안 노이즈가 추가될 수 있다.

- 또는 무작위로 입력을 switched-off 할 수 있다. (like Dropout)

<div style="text-align:center">
  <img src="https://user-images.githubusercontent.com/33220404/145705905-0ec38f7b-0862-45dd-9246-9a7bbc66ab11.png" width="400">
</div>

**DAE architecture**

- 1. Add Gaussian noise

- 2. Dropout

### Results of Denoising autio-encoder

<div style="text-align:center">
  <img src="https://user-images.githubusercontent.com/33220404/145705956-7f1afdc0-89d1-41e4-9429-ac9e8c736f48.png" width="600">
</div>

<br />

## Variational Autoencoders (VAE)

이전의 AE들은 입력 데이터가 인코더를 통해 데이의 특징을 나타내는 하나의 인코더 벡터(= 코딩)으로 변형되었다. 즉, 이 인코더들은 하나의 single value를 출력했었고, 디코더는 이 값을 사용해 원본 데이터를 복원하도록 학습이 되었다.

> 반면에 Variational(변이형) AE는 latent space(잠재 공간)애서의 관찰을 설명하는 확률적 방식이다. 즉, VAE의 인코더는 각 특징을 설명하는 single value를 출력하는 것이 아닌, 각 latent attribute에 대한 확률 분포를 출력한다.

VAE의 특징

- **Probabilistic(확률적) AE** - 트레이닝이 끝난 후에도 출력이 부분적으로 우연에 의해 결정된다. (반면에 DAE는 트레이닝 시에만 무작위성을 사용한다.)

- **Generative(생성) AE** - 트레이닝 세트에서 샘플링된 것 같은 새로운 샘플을 생성한다.

<br />

### VAE의 작동 방식

인코더 뒤에 디코더가 따르는 기본 구조를 가지고 있다.

주어진 입력에 대한 코딩을 바로 만드는 대신, 인코더가 **평균 코딩 μ와 표준편차 σ를 만든다.** 

- 실제 코딩은 평균이 μ이고 표준편차가 σ인 가우시안 분포에서 **랜덤하게 샘플링** 된다.

그 후 디코더가 샘플링된 코딩을 보통처럼 디코딩한다.

<br />

<div style="text-align:center">
  <img src="https://user-images.githubusercontent.com/33220404/145706209-8deec188-c10c-4942-bd50-3e27a67ed917.png" width="500">
</div>

(위 이미지는 VAE(왼쪽)와 이를 통과하는 샘플(오른쪽)을 보여준다.)

1. 인코더가 μ와 σ를 만들면 코딩이 랜덤하게 선택된다.

2. 코딩이 디코드되어 훈련 샘플을 닮은 최종 출력을 만든다.

<br />

VAE는 입력이 복잡한 분포를 가지더라도, **간단한 가우시안 분포에서 샘플링된 것처럼 보이는 코딩을 만드는 경향**이 있다.

훈련하는 동안 비용 함수가 코딩을 **가우시안 샘플들의 군집처럼 보이도록 코딩 공간(잠재 공간) 안으로 점진적으로 이동시킨다.**

➡️ VAE가 훈련이 끝난 뒤 새로운 샘플을 매우 쉽게 생성할 수 있다.

**=> 즉, 가우시안 분포에서 랜덤한 코딩을 샘플링 해 디코딩하면 된다.**

<br />
<br />

**Source:**

📖 핸즈온머신러닝, 2/E, 2020 (번역)